{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad6494c-e460-4094-bb71-ae531af1f8a8",
   "metadata": {},
   "source": [
    "# Interactive LLM Chatbot Arena Domain Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c241c261-7d84-4f28-92ab-4d147004d5ac",
   "metadata": {},
   "source": [
    "## Simply run the two cells below to start interacting with our classifier! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b910404c-6659-4ec2-a13c-b201c15ff7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder.joblib']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from dash import Dash, dcc, html, Input, Output\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "df = pd.read_csv(\"sampled_dataset.csv\")\n",
    "valid_domains = ['opinion', 'creative', 'factual', 'code', 'math']\n",
    "df = df[df['Domain'].isin(valid_domains)].copy()\n",
    "df = df[df['Open/Closed'].isin(['open', 'closed'])].copy()\n",
    "\n",
    "# Prepare combined text and labels\n",
    "df[\"combined_text\"] = df[\"Open/Closed\"] + \" [SEP] \" + df[\"prompt\"].astype(str)\n",
    "le = LabelEncoder()\n",
    "df[\"domain_label\"] = le.fit_transform(df[\"Domain\"])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"combined_text\"], df[\"domain_label\"], test_size=0.2, random_state=42, stratify=df[\"domain_label\"]\n",
    ")\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=3000, stop_words='english', ngram_range=(1, 2))\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Train SVM with RBF kernel using GridSearch\n",
    "param_grid = {'C': [1, 10], 'gamma': ['scale', 0.01]}\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "grid = GridSearchCV(svm, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train_vec, y_train)\n",
    "best_svm_oc = grid.best_estimator_\n",
    "\n",
    "y_pred = best_svm_oc.predict(X_test_vec)\n",
    "#print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))\n",
    "\n",
    "\n",
    "# Save files \n",
    "joblib.dump(best_svm_oc, \"best_svm_oc.joblib\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.joblib\")\n",
    "joblib.dump(le, \"label_encoder.joblib\")\n",
    "#print(\"Files saved: best_svm_oc.joblib, tfidf_vectorizer.joblib, label_encoder.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2eb6a43-514e-40db-9168-883eacf17b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://0.0.0.0:10000/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x12c2962d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "from dash import Dash, dcc, html, Input, Output, State\n",
    "\n",
    "# Load trained model and vectorizer/encoder\n",
    "model = joblib.load(\"best_svm_model.joblib\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.joblib\")\n",
    "label_encoder = joblib.load(\"label_encoder.joblib\")\n",
    "\n",
    "# Initialize Dash app\n",
    "app = Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"ü§ñ LLM Arena: Chatbot Domain Classifier\", \n",
    "            style={\"textAlign\": \"center\", \"fontFamily\": \"Arial\", \"marginTop\": \"30px\"}),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.Textarea(\n",
    "            id='user_input',\n",
    "            placeholder='üí¨ Type your prompt here...',\n",
    "            style={\n",
    "                'width': '100%',\n",
    "                'height': '150px',\n",
    "                'borderRadius': '10px',\n",
    "                'padding': '10px',\n",
    "                'fontSize': '16px',\n",
    "                'fontFamily': 'Courier New',\n",
    "                'boxShadow': '0 0 5px rgba(0,0,0,0.1)'\n",
    "            }\n",
    "        ),\n",
    "        html.Button('üöÄ Classify Domain', id='predict_button', n_clicks=0, \n",
    "                    style={\n",
    "                        'marginTop': '10px',\n",
    "                        'padding': '10px 20px',\n",
    "                        'fontSize': '16px',\n",
    "                        'borderRadius': '5px',\n",
    "                        'backgroundColor': '#007BFF',\n",
    "                        'color': 'white',\n",
    "                        'border': 'none',\n",
    "                        'cursor': 'pointer'\n",
    "                    }),\n",
    "        html.Div(id='prediction_output', \n",
    "                 style={\n",
    "                     'marginTop': '20px', \n",
    "                     'fontWeight': 'bold',\n",
    "                     'fontSize': '20px',\n",
    "                     'color': '#2E8B57'\n",
    "                 })\n",
    "    ], style={\n",
    "        'maxWidth': '700px', \n",
    "        'margin': 'auto', \n",
    "        'padding': '20px',\n",
    "        'backgroundColor': '#F9F9F9',\n",
    "        'borderRadius': '10px',\n",
    "        'boxShadow': '0 0 10px rgba(0,0,0,0.05)'\n",
    "    }),\n",
    "\n",
    "    # ‚Üê This comma is the critical fix\n",
    "\n",
    "    html.Div(id='correction_section', children=[\n",
    "        html.Label(\"Was this prediction correct? If not, choose the correct domain:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='correction_dropdown',\n",
    "            options=[{'label': d, 'value': d} for d in label_encoder.classes_],\n",
    "            placeholder='Select correct domain...',\n",
    "            style={'marginTop': '10px'}\n",
    "        ),\n",
    "        html.Button(\"‚úÖ Submit Correction\", id='submit_correction', n_clicks=0,\n",
    "                    style={\n",
    "                        'marginTop': '10px',\n",
    "                        'padding': '8px 16px',\n",
    "                        'backgroundColor': '#28a745',\n",
    "                        'color': 'white',\n",
    "                        'border': 'none',\n",
    "                        'borderRadius': '5px',\n",
    "                        'cursor': 'pointer'\n",
    "                    }),\n",
    "        html.Div(id='correction_feedback', style={'marginTop': '10px', 'color': '#444'})\n",
    "    ])\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('prediction_output', 'children'),\n",
    "    Input('predict_button', 'n_clicks'),\n",
    "    Input('user_input', 'value')\n",
    ")\n",
    "def classify_domain(n_clicks, text):\n",
    "    if n_clicks > 0 and text:\n",
    "        X = vectorizer.transform([text])\n",
    "        pred = model.predict(X)\n",
    "        domain = label_encoder.inverse_transform(pred)[0]\n",
    "        return f\"Predicted Domain: {domain}\"\n",
    "    return \"\"\n",
    "\n",
    "@app.callback(\n",
    "    Output('correction_feedback', 'children'),\n",
    "    Input('submit_correction', 'n_clicks'),\n",
    "    State('user_input', 'value'),\n",
    "    State('correction_dropdown', 'value')\n",
    ")\n",
    "def save_correction(n_clicks, user_text, corrected_label):\n",
    "    if n_clicks > 0 and user_text and corrected_label:\n",
    "        with open(\"corrections.csv\", \"a\") as f:\n",
    "            f.write(f'\"{user_text.strip()}\",{corrected_label}\\n')\n",
    "        return \"‚úÖ Correction saved! Thanks for helping improve the model.\"\n",
    "    return \"\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    port = int(os.environ.get(\"PORT\", 10000))  # Render sets PORT dynamically\n",
    "    app.run_server(debug=False, host=\"0.0.0.0\", port=port)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "546e7051-07e8-427b-94b9-30d755b05b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11 corrections from corrections.csv\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        code       0.83      0.33      0.48        15\n",
      "    creative       0.91      0.67      0.77        30\n",
      "     factual       0.49      0.77      0.60        35\n",
      "        math       0.40      0.20      0.27        10\n",
      "     opinion       0.59      0.64      0.62        25\n",
      "\n",
      "    accuracy                           0.61       115\n",
      "   macro avg       0.65      0.52      0.55       115\n",
      "weighted avg       0.66      0.61      0.60       115\n",
      "\n",
      "Updated model, vectorizer, and label encoder saved\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load base dataset\n",
    "df = pd.read_csv(\"sampled_dataset.csv\")\n",
    "df = df[df['Domain'].isin(['opinion', 'creative', 'factual', 'code', 'math'])].copy()\n",
    "df = df[df['Open/Closed'].isin(['open', 'closed'])].copy()\n",
    "df[\"combined_text\"] = df[\"Open/Closed\"] + \" [SEP] \" + df[\"prompt\"].astype(str)\n",
    "df[\"domain_label\"] = df[\"Domain\"]  # Will re-encode below\n",
    "\n",
    "# Load corrections if file exists\n",
    "try:\n",
    "    corrections = pd.read_csv(\"corrections.csv\", header=None, names=[\"prompt\", \"correct_domain\"])\n",
    "    corrections[\"combined_text\"] = \"open [SEP] \" + corrections[\"prompt\"].astype(str)  # default to 'open' or update if known\n",
    "    corrections[\"domain_label\"] = corrections[\"correct_domain\"]\n",
    "    df = pd.concat([df[[\"combined_text\", \"domain_label\"]], corrections[[\"combined_text\", \"domain_label\"]]], ignore_index=True)\n",
    "    print(f\"Loaded {len(corrections)} corrections from corrections.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è No corrections.csv found. Proceeding with original dataset.\")\n",
    "\n",
    "# Encode domain labels\n",
    "le = LabelEncoder()\n",
    "df[\"domain_encoded\"] = le.fit_transform(df[\"domain_label\"])\n",
    "\n",
    "# TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=3000, stop_words='english', ngram_range=(1, 2))\n",
    "X = vectorizer.fit_transform(df[\"combined_text\"])\n",
    "y = df[\"domain_encoded\"]\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# SVM + GridSearchCV\n",
    "param_grid = {'C': [1, 10], 'gamma': ['scale', 0.01]}\n",
    "svm = SVC(kernel='rbf', random_state=42)\n",
    "grid = GridSearchCV(svm, param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "# Evaluate\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "\n",
    "\n",
    "joblib.dump(best_model, \"best_svm_model.joblib\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.joblib\")\n",
    "joblib.dump(le, \"label_encoder.joblib\")\n",
    "\n",
    "print(\"Updated model, vectorizer, and label encoder saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62079cc5-fd11-4cdf-bccc-98382f8e9a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
