{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/doga/Desktop/chatbot arena project/cbot/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fastparquet\n",
    "import pyarrow\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>judge</th>\n",
       "      <th>conversation_a</th>\n",
       "      <th>conversation_b</th>\n",
       "      <th>turn</th>\n",
       "      <th>anony</th>\n",
       "      <th>language</th>\n",
       "      <th>tstamp</th>\n",
       "      <th>openai_moderation</th>\n",
       "      <th>toxic_chat_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58210e39b3fd4441a2bd4a518bb44c2d</td>\n",
       "      <td>chatglm-6b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>[{'content': 'What is the difference between O...</td>\n",
       "      <td>[{'content': 'What is the difference between O...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'categories': {'harassment': False, 'harassme...</td>\n",
       "      <td>{'roberta-large': {'flagged': False, 'probabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2564acd09e3942fd97657d05282d4389</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>alpaca-13b</td>\n",
       "      <td>tie</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>[{'content': 'Why did my parent not invite me ...</td>\n",
       "      <td>[{'content': 'Why did my parent not invite me ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'categories': {'harassment': False, 'harassme...</td>\n",
       "      <td>{'roberta-large': {'flagged': False, 'probabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90bfd142157948aba01931726c888e7f</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>[{'content': 'Fuji vs. Nikon, which is better?...</td>\n",
       "      <td>[{'content': 'Fuji vs. Nikon, which is better?...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'categories': {'harassment': False, 'harassme...</td>\n",
       "      <td>{'roberta-large': {'flagged': False, 'probabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a7c5accc53e649a3bc6b2e41d962ebc4</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>oasst-pythia-12b</td>\n",
       "      <td>model_b</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>[{'content': 'How to build an arena for chatbo...</td>\n",
       "      <td>[{'content': 'How to build an arena for chatbo...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'categories': {'harassment': False, 'harassme...</td>\n",
       "      <td>{'roberta-large': {'flagged': False, 'probabil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adf27e819a3c494cb6e993f0c660e097</td>\n",
       "      <td>vicuna-13b</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>model_a</td>\n",
       "      <td>arena_user_973</td>\n",
       "      <td>[{'content': 'When is it today?', 'role': 'use...</td>\n",
       "      <td>[{'content': 'When is it today?', 'role': 'use...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>English</td>\n",
       "      <td>1.682352e+09</td>\n",
       "      <td>{'categories': {'harassment': False, 'harassme...</td>\n",
       "      <td>{'roberta-large': {'flagged': False, 'probabil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        question_id           model_a           model_b  \\\n",
       "0  58210e39b3fd4441a2bd4a518bb44c2d        chatglm-6b         koala-13b   \n",
       "1  2564acd09e3942fd97657d05282d4389  oasst-pythia-12b        alpaca-13b   \n",
       "2  90bfd142157948aba01931726c888e7f         koala-13b  oasst-pythia-12b   \n",
       "3  a7c5accc53e649a3bc6b2e41d962ebc4        vicuna-13b  oasst-pythia-12b   \n",
       "4  adf27e819a3c494cb6e993f0c660e097        vicuna-13b         koala-13b   \n",
       "\n",
       "    winner           judge                                     conversation_a  \\\n",
       "0  model_b  arena_user_973  [{'content': 'What is the difference between O...   \n",
       "1      tie  arena_user_973  [{'content': 'Why did my parent not invite me ...   \n",
       "2  model_b  arena_user_973  [{'content': 'Fuji vs. Nikon, which is better?...   \n",
       "3  model_b  arena_user_973  [{'content': 'How to build an arena for chatbo...   \n",
       "4  model_a  arena_user_973  [{'content': 'When is it today?', 'role': 'use...   \n",
       "\n",
       "                                      conversation_b  turn  anony language  \\\n",
       "0  [{'content': 'What is the difference between O...     1   True  English   \n",
       "1  [{'content': 'Why did my parent not invite me ...     1   True  English   \n",
       "2  [{'content': 'Fuji vs. Nikon, which is better?...     1   True  English   \n",
       "3  [{'content': 'How to build an arena for chatbo...     1   True  English   \n",
       "4  [{'content': 'When is it today?', 'role': 'use...     1   True  English   \n",
       "\n",
       "         tstamp                                  openai_moderation  \\\n",
       "0  1.682352e+09  {'categories': {'harassment': False, 'harassme...   \n",
       "1  1.682352e+09  {'categories': {'harassment': False, 'harassme...   \n",
       "2  1.682352e+09  {'categories': {'harassment': False, 'harassme...   \n",
       "3  1.682352e+09  {'categories': {'harassment': False, 'harassme...   \n",
       "4  1.682352e+09  {'categories': {'harassment': False, 'harassme...   \n",
       "\n",
       "                                      toxic_chat_tag  \n",
       "0  {'roberta-large': {'flagged': False, 'probabil...  \n",
       "1  {'roberta-large': {'flagged': False, 'probabil...  \n",
       "2  {'roberta-large': {'flagged': False, 'probabil...  \n",
       "3  {'roberta-large': {'flagged': False, 'probabil...  \n",
       "4  {'roberta-large': {'flagged': False, 'probabil...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"hf://datasets/lmsys/chatbot_arena_conversations/data/train-00000-of-00001-cced8514c7ed782a.parquet\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{\"role\": \"user\", \"content\": \"...\"} -> [0]\n",
    "#{\"role\": \"assistant\", \"content\": \"...\"} -> [1]\n",
    "#content matches dictionay prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>human_winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the difference between OpenCL and CUDA?</td>\n",
       "      <td>OpenCL and CUDA are two different programming ...</td>\n",
       "      <td>OpenCL and CUDA are both programming languages...</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why did my parent not invite me to their wedding?</td>\n",
       "      <td>It is possible that your parent did not invite...</td>\n",
       "      <td>It is likely that they wanted to keep the gues...</td>\n",
       "      <td>tie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fuji vs. Nikon, which is better?</td>\n",
       "      <td>Both Fuji and Nikon are popular camera brands ...</td>\n",
       "      <td>This is a subjective question and the answer d...</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How to build an arena for chatbots?</td>\n",
       "      <td>Building an arena for chatbots can be done by ...</td>\n",
       "      <td>Building an arena for chatbots is a great way ...</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When is it today?</td>\n",
       "      <td>I'm sorry, I cannot determine the current date...</td>\n",
       "      <td>Today is February 23, 2023.</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0    What is the difference between OpenCL and CUDA?   \n",
       "1  Why did my parent not invite me to their wedding?   \n",
       "2                   Fuji vs. Nikon, which is better?   \n",
       "3                How to build an arena for chatbots?   \n",
       "4                                  When is it today?   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  OpenCL and CUDA are two different programming ...   \n",
       "1  It is possible that your parent did not invite...   \n",
       "2  Both Fuji and Nikon are popular camera brands ...   \n",
       "3  Building an arena for chatbots can be done by ...   \n",
       "4  I'm sorry, I cannot determine the current date...   \n",
       "\n",
       "                                          response_b human_winner  \n",
       "0  OpenCL and CUDA are both programming languages...      model_b  \n",
       "1  It is likely that they wanted to keep the gues...          tie  \n",
       "2  This is a subjective question and the answer d...      model_b  \n",
       "3  Building an arena for chatbots is a great way ...      model_b  \n",
       "4                        Today is February 23, 2023.      model_a  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_info(row):\n",
    "    try:\n",
    "        prompt = row[\"conversation_a\"][0][\"content\"]\n",
    "        response_a = row[\"conversation_a\"][1][\"content\"]\n",
    "        response_b = row[\"conversation_b\"][1][\"content\"]\n",
    "        winner = row[\"winner\"]\n",
    "        return pd.Series([prompt, response_a, response_b, winner])\n",
    "    except Exception:\n",
    "        return pd.Series([None, None, None, None])\n",
    "\n",
    "df_extracted = df.apply(extract_info, axis=1)\n",
    "df_extracted.columns = [\"prompt\", \"response_a\", \"response_b\", \"human_winner\"]\n",
    "df_extracted.dropna(inplace=True)\n",
    "# df_extracted.to_csv(\"chatbot_arena_extracted.csv\", index=False)\n",
    "df_extracted.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample 100 rows\n",
    "sampled_df = df_extracted.sample(n=100, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT scoring \n",
    "import openai\n",
    "import time\n",
    "\n",
    "openai.api_key = [\"YOUR_OPENAI_API_KEY\"]\n",
    "\n",
    "def gpt4_judgment(prompt, response_a, response_b):\n",
    "    system_prompt = \"\"\"You are a helpful assistant that evaluates the factual correctness, coherence, and clarity of two AI-generated responses to a user prompt. You must pick which one is better, or state if they are equal.\"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "Prompt: {prompt}\n",
    "\n",
    "Response A: {response_a}\n",
    "\n",
    "Response B: {response_b}\n",
    "\n",
    "Which response is better? Reply with one of: 'A', 'B', or 'tie'.\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        res = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0\n",
    "        )\n",
    "        decision = res['choices'][0]['message']['content'].strip().lower()\n",
    "        if 'a' in decision and 'b' not in decision:\n",
    "            return \"model_a\"\n",
    "        elif 'b' in decision and 'a' not in decision:\n",
    "            return \"model_b\"\n",
    "        elif \"tie\" in decision:\n",
    "            return \"tie\"\n",
    "        else:\n",
    "            return \"unknown\"\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "        return \"error\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n",
      "Error: The model `gpt-4` does not exist or you do not have access to it.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>human_winner</th>\n",
       "      <th>gpt_winner</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>write me a weeding speech in Albanian</td>\n",
       "      <td>Here it is:\\n\\n\"Albana, the land of the Albani...</td>\n",
       "      <td>Përshëndetje të gjithëve,\\n\\nSot jemi të bashk...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISO 26262: technical requiremen for functional...</td>\n",
       "      <td>The technical requirements for the functional ...</td>\n",
       "      <td>ISO 26262 is a standard for the development of...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the Adam</td>\n",
       "      <td>Adam is a biblical figure in the Hebrew Bible ...</td>\n",
       "      <td>Adam is a first-order optimization algorithm t...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schreibe ein Gedicht über Kaninchen.</td>\n",
       "      <td>In einem Land, so grün und weit,\\nda hüpft ein...</td>\n",
       "      <td>Zarte Ohren, flauschiges Fell,\\nKaninchen hopp...</td>\n",
       "      <td>tie</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explique moi comment je peux ressembler a lair...</td>\n",
       "      <td>L'art de ressembler à Laird Miehud est un exer...</td>\n",
       "      <td>dans le futur vous pouvez vous présenter comme...</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0              write me a weeding speech in Albanian   \n",
       "1  ISO 26262: technical requiremen for functional...   \n",
       "2                                   what is the Adam   \n",
       "3               Schreibe ein Gedicht über Kaninchen.   \n",
       "4  explique moi comment je peux ressembler a lair...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Here it is:\\n\\n\"Albana, the land of the Albani...   \n",
       "1  The technical requirements for the functional ...   \n",
       "2  Adam is a biblical figure in the Hebrew Bible ...   \n",
       "3  In einem Land, so grün und weit,\\nda hüpft ein...   \n",
       "4  L'art de ressembler à Laird Miehud est un exer...   \n",
       "\n",
       "                                          response_b   human_winner  \\\n",
       "0  Përshëndetje të gjithëve,\\n\\nSot jemi të bashk...        model_b   \n",
       "1  ISO 26262 is a standard for the development of...        model_a   \n",
       "2  Adam is a first-order optimization algorithm t...        model_a   \n",
       "3  Zarte Ohren, flauschiges Fell,\\nKaninchen hopp...            tie   \n",
       "4  dans le futur vous pouvez vous présenter comme...  tie (bothbad)   \n",
       "\n",
       "  gpt_winner label  \n",
       "0      error  None  \n",
       "1      error  None  \n",
       "2      error  None  \n",
       "3      error  None  \n",
       "4      error  None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#row labeling\n",
    "def label_row(row):\n",
    "    gpt_winner = gpt4_judgment(row[\"prompt\"], row[\"response_a\"], row[\"response_b\"])\n",
    "    row[\"gpt_winner\"] = gpt_winner\n",
    "    row[\"label\"] = int(gpt_winner == row[\"human_winner\"]) if gpt_winner in [\"model_a\", \"model_b\"] else None\n",
    "    return row\n",
    "\n",
    "labeled_df = sampled_df.apply(label_row, axis=1)\n",
    "#labeled_df.to_csv(\"labeled_chatbot_judgments.csv\", index=False)\n",
    "labeled_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def encode_text(text):\n",
    "    return model.encode(text)\n",
    "\n",
    "#calculate similarity between two embeddings\n",
    "def calculate_similarity(embedding_a, embedding_b):\n",
    "    return cosine_similarity([embedding_a], [embedding_b])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the text\n",
    "labeled_df['prompt_embedding'] = labeled_df['prompt'].apply(encode_text)\n",
    "labeled_df['response_a_embedding'] = labeled_df['response_a'].apply(encode_text)\n",
    "labeled_df['response_b_embedding'] = labeled_df['response_b'].apply(encode_text)\n",
    "\n",
    "#calculate similarity between the embeddings\n",
    "labeled_df['similarity_a_b'] = labeled_df.apply(lambda row: calculate_similarity(row['prompt_embedding'], row['response_a_embedding']), axis=1)\n",
    "labeled_df['similarity_a_c'] = labeled_df.apply(lambda row: calculate_similarity(row['prompt_embedding'], row['response_b_embedding']), axis=1)\n",
    "labeled_df['similarity_b_c'] = labeled_df.apply(lambda row: calculate_similarity(row['response_a_embedding'], row['response_b_embedding']), axis=1)\n",
    "\n",
    "labeled_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>human_winner</th>\n",
       "      <th>gpt_winner</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_embedding</th>\n",
       "      <th>response_a_embedding</th>\n",
       "      <th>response_b_embedding</th>\n",
       "      <th>similarity_a_b</th>\n",
       "      <th>similarity_a_c</th>\n",
       "      <th>similarity_b_c</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>write me a weeding speech in Albanian</td>\n",
       "      <td>Here it is:\\n\\n\"Albana, the land of the Albani...</td>\n",
       "      <td>Përshëndetje të gjithëve,\\n\\nSot jemi të bashk...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.00090263964, 0.08146245, -0.019265478, 0.02...</td>\n",
       "      <td>[-0.019966735, 0.118588835, -0.0032393907, 0.0...</td>\n",
       "      <td>[-0.05448748, 0.08408137, 0.09397893, -0.03848...</td>\n",
       "      <td>0.561416</td>\n",
       "      <td>0.231599</td>\n",
       "      <td>0.093901</td>\n",
       "      <td>[0.0009026396437548101, 0.08146245032548904, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISO 26262: technical requiremen for functional...</td>\n",
       "      <td>The technical requirements for the functional ...</td>\n",
       "      <td>ISO 26262 is a standard for the development of...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.050106883, 0.01170723, -0.077458605, 0.010...</td>\n",
       "      <td>[-0.032367595, 0.018893026, -0.064028434, 0.00...</td>\n",
       "      <td>[-0.01591786, 0.010488646, -0.079126835, 0.027...</td>\n",
       "      <td>0.769802</td>\n",
       "      <td>0.766539</td>\n",
       "      <td>0.711753</td>\n",
       "      <td>[-0.05010688304901123, 0.011707229539752007, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the Adam</td>\n",
       "      <td>Adam is a biblical figure in the Hebrew Bible ...</td>\n",
       "      <td>Adam is a first-order optimization algorithm t...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.031983335, 0.029641649, 0.0231351, -0.0011...</td>\n",
       "      <td>[0.035256937, 0.06237943, 0.00058803515, 0.027...</td>\n",
       "      <td>[-0.09135917, -0.022418719, 0.03546467, -0.037...</td>\n",
       "      <td>0.716471</td>\n",
       "      <td>0.525721</td>\n",
       "      <td>0.343163</td>\n",
       "      <td>[-0.03198333457112312, 0.0296416487544775, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Schreibe ein Gedicht über Kaninchen.</td>\n",
       "      <td>In einem Land, so grün und weit,\\nda hüpft ein...</td>\n",
       "      <td>Zarte Ohren, flauschiges Fell,\\nKaninchen hopp...</td>\n",
       "      <td>tie</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.092044756, 0.090163745, 0.012006649, 0.0057...</td>\n",
       "      <td>[-0.03834474, 0.017420044, -0.037667282, 0.019...</td>\n",
       "      <td>[-0.0320743, 0.013008292, -0.031750686, 0.0277...</td>\n",
       "      <td>0.348308</td>\n",
       "      <td>0.356203</td>\n",
       "      <td>0.593323</td>\n",
       "      <td>[0.09204475581645966, 0.09016374498605728, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>explique moi comment je peux ressembler a lair...</td>\n",
       "      <td>L'art de ressembler à Laird Miehud est un exer...</td>\n",
       "      <td>dans le futur vous pouvez vous présenter comme...</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>error</td>\n",
       "      <td>None</td>\n",
       "      <td>[-0.062433362, 0.039559808, 0.0035601135, -0.0...</td>\n",
       "      <td>[-0.0604297, 0.014287303, -0.0125871375, -0.12...</td>\n",
       "      <td>[-0.042159673, 0.05592871, -0.056610413, -0.03...</td>\n",
       "      <td>0.490012</td>\n",
       "      <td>0.308307</td>\n",
       "      <td>0.352538</td>\n",
       "      <td>[-0.06243336200714111, 0.03955980762839317, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0              write me a weeding speech in Albanian   \n",
       "1  ISO 26262: technical requiremen for functional...   \n",
       "2                                   what is the Adam   \n",
       "3               Schreibe ein Gedicht über Kaninchen.   \n",
       "4  explique moi comment je peux ressembler a lair...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  Here it is:\\n\\n\"Albana, the land of the Albani...   \n",
       "1  The technical requirements for the functional ...   \n",
       "2  Adam is a biblical figure in the Hebrew Bible ...   \n",
       "3  In einem Land, so grün und weit,\\nda hüpft ein...   \n",
       "4  L'art de ressembler à Laird Miehud est un exer...   \n",
       "\n",
       "                                          response_b   human_winner  \\\n",
       "0  Përshëndetje të gjithëve,\\n\\nSot jemi të bashk...        model_b   \n",
       "1  ISO 26262 is a standard for the development of...        model_a   \n",
       "2  Adam is a first-order optimization algorithm t...        model_a   \n",
       "3  Zarte Ohren, flauschiges Fell,\\nKaninchen hopp...            tie   \n",
       "4  dans le futur vous pouvez vous présenter comme...  tie (bothbad)   \n",
       "\n",
       "  gpt_winner label                                   prompt_embedding  \\\n",
       "0      error  None  [0.00090263964, 0.08146245, -0.019265478, 0.02...   \n",
       "1      error  None  [-0.050106883, 0.01170723, -0.077458605, 0.010...   \n",
       "2      error  None  [-0.031983335, 0.029641649, 0.0231351, -0.0011...   \n",
       "3      error  None  [0.092044756, 0.090163745, 0.012006649, 0.0057...   \n",
       "4      error  None  [-0.062433362, 0.039559808, 0.0035601135, -0.0...   \n",
       "\n",
       "                                response_a_embedding  \\\n",
       "0  [-0.019966735, 0.118588835, -0.0032393907, 0.0...   \n",
       "1  [-0.032367595, 0.018893026, -0.064028434, 0.00...   \n",
       "2  [0.035256937, 0.06237943, 0.00058803515, 0.027...   \n",
       "3  [-0.03834474, 0.017420044, -0.037667282, 0.019...   \n",
       "4  [-0.0604297, 0.014287303, -0.0125871375, -0.12...   \n",
       "\n",
       "                                response_b_embedding  similarity_a_b  \\\n",
       "0  [-0.05448748, 0.08408137, 0.09397893, -0.03848...        0.561416   \n",
       "1  [-0.01591786, 0.010488646, -0.079126835, 0.027...        0.769802   \n",
       "2  [-0.09135917, -0.022418719, 0.03546467, -0.037...        0.716471   \n",
       "3  [-0.0320743, 0.013008292, -0.031750686, 0.0277...        0.348308   \n",
       "4  [-0.042159673, 0.05592871, -0.056610413, -0.03...        0.490012   \n",
       "\n",
       "   similarity_a_c  similarity_b_c  \\\n",
       "0        0.231599        0.093901   \n",
       "1        0.766539        0.711753   \n",
       "2        0.525721        0.343163   \n",
       "3        0.356203        0.593323   \n",
       "4        0.308307        0.352538   \n",
       "\n",
       "                                            features  \n",
       "0  [0.0009026396437548101, 0.08146245032548904, -...  \n",
       "1  [-0.05010688304901123, 0.011707229539752007, -...  \n",
       "2  [-0.03198333457112312, 0.0296416487544775, 0.0...  \n",
       "3  [0.09204475581645966, 0.09016374498605728, 0.0...  \n",
       "4  [-0.06243336200714111, 0.03955980762839317, 0....  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def combine_features(row):\n",
    "    return np.concatenate([\n",
    "        row['prompt_embedding'],\n",
    "        row['response_a_embedding'],\n",
    "        row['response_b_embedding'],\n",
    "        [row['similarity_a_b']],\n",
    "        [row['similarity_a_c']],\n",
    "        [row['similarity_b_c']]\n",
    "    ])\n",
    "\n",
    "labeled_df['features'] = labeled_df.apply(combine_features, axis=1)\n",
    "labeled_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #prepare labels\n",
    "# labeled_df = labeled_df.dropna(subset=['label'])\n",
    "# labels = labeled_df['label'].values\n",
    "\n",
    "# #split\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = np.stack(labeled_df['features'].values)\n",
    "# y = labels\n",
    "\n",
    "# #train a random forest classifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# clf = RandomForestClassifier()\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Accuracy:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#filter 0\n",
    "misaligned_df = labeled_df[labeled_df[\"label\"] == 0].copy()\n",
    "misaligned_df.head(5)\n",
    "misaligned_df.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No misaligned samples available!\n"
     ]
    }
   ],
   "source": [
    "if len(misaligned_df) == 0:\n",
    "    print(\"No misaligned samples available!\")\n",
    "else:\n",
    "    sampled_data = misaligned_df.sample(n=500, random_state=42, replace=True)\n",
    "    print(sampled_data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify closed ended and open ended prompts\n",
    "patterns = [\n",
    "    {\"label\": \"MATH\", \"pattern\": [{\"LOWER\": {\"IN\": [\n",
    "        \"add\", \"subtract\", \"multiply\", \"divide\", \"equation\", \"integral\", \"derivative\", \"mathematics\",\n",
    "        \"algebra\", \"geometry\", \"trigonometry\", \"calculus\", \"limit\", \"logarithm\", \"exponent\", \"modulus\",\n",
    "        \"matrix\", \"vector\", \"scalar\", \"mean\", \"median\", \"mode\", \"standard deviation\", \"variance\",\n",
    "        \"probability\", \"distribution\", \"combination\", \"permutation\", \"function\", \"identity\", \"root\",\n",
    "        \"square\", \"cube\", \"angle\", \"theorem\", \"proof\", \"hypothesis\", \"corollary\", \"lemma\"\n",
    "    ]}}]},\n",
    "    \n",
    "    {\"label\": \"NUMBER\", \"pattern\": [{\"LIKE_NUM\": True}]},\n",
    "    \n",
    "    {\"label\": \"CODE\", \"pattern\": [{\"LOWER\": {\"IN\": [\n",
    "        \"function\", \"variable\", \"loop\", \"class\", \"object\", \"array\", \"list\", \"dictionary\",\n",
    "        \"string\", \"integer\", \"float\", \"boolean\", \"if\", \"else\", \"elif\", \"switch\", \"case\", \"for\",\n",
    "        \"while\", \"break\", \"continue\", \"return\", \"import\", \"def\", \"try\", \"except\", \"finally\",\n",
    "        \"with\", \"as\", \"yield\", \"lambda\", \"none\", \"true\", \"false\"\n",
    "    ]}}]}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "for pattern in patterns:\n",
    "    matcher.add(pattern[\"label\"], [pattern[\"pattern\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_terms(prompt):\n",
    "    doc = nlp(prompt)\n",
    "    matches = matcher(doc)\n",
    "    detected_terms = set()\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        detected_terms.add((nlp.vocab.strings[match_id], span.text))\n",
    "    return detected_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sampled_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdetected_terms\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msampled_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(detect_terms)\n\u001b[1;32m      2\u001b[0m sampled_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampled_data' is not defined"
     ]
    }
   ],
   "source": [
    "sampled_data['detected_terms'] = sampled_data['prompt'].apply(detect_terms)\n",
    "sampled_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>human_winner</th>\n",
       "      <th>gpt_winner</th>\n",
       "      <th>label</th>\n",
       "      <th>prompt_embedding</th>\n",
       "      <th>response_a_embedding</th>\n",
       "      <th>response_b_embedding</th>\n",
       "      <th>similarity_a_b</th>\n",
       "      <th>similarity_a_c</th>\n",
       "      <th>similarity_b_c</th>\n",
       "      <th>features</th>\n",
       "      <th>detected_terms</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Tell me a joke</td>\n",
       "      <td>Why did the carrot turn red?\\n\\nBecause it saw...</td>\n",
       "      <td>A construction worker was walking when crashed...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>model_a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.013610002, -0.035938635, 0.02055572, 0.002...</td>\n",
       "      <td>[-0.050809518, -0.025566049, -0.0257295, 0.102...</td>\n",
       "      <td>[-0.05158351, 0.022370216, 0.03135999, 0.06952...</td>\n",
       "      <td>0.156050</td>\n",
       "      <td>0.210762</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>[-0.013610001653432846, -0.03593863546848297, ...</td>\n",
       "      <td>{}</td>\n",
       "      <td>Open-ended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>What is the industrial revolution?</td>\n",
       "      <td>The Industrial Revolution refers to a period o...</td>\n",
       "      <td>The industrial revolution was a significant pe...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>model_a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.025486542, 0.0061054714, -0.045459997, -0....</td>\n",
       "      <td>[-0.0524989, -0.004233326, 0.00977435, 0.00209...</td>\n",
       "      <td>[-0.012855443, 0.004006175, 0.021647064, -0.02...</td>\n",
       "      <td>0.718032</td>\n",
       "      <td>0.749566</td>\n",
       "      <td>0.858142</td>\n",
       "      <td>[-0.025486541911959648, 0.0061054714024066925,...</td>\n",
       "      <td>{}</td>\n",
       "      <td>Open-ended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>what is a Calabi-Yau manifold ?\\n\\nAnswer:</td>\n",
       "      <td>A Calabi-Yau manifold is a type of mathematica...</td>\n",
       "      <td>A Calabi-Yau manifold is a complex manifold th...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>model_a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.010430147, 0.028473515, -0.055231307, -0.0...</td>\n",
       "      <td>[-0.03338751, -0.04724372, -0.050808728, 0.015...</td>\n",
       "      <td>[-0.047239825, 0.028733192, -0.03291552, 0.004...</td>\n",
       "      <td>0.734846</td>\n",
       "      <td>0.858537</td>\n",
       "      <td>0.844449</td>\n",
       "      <td>[-0.01043014694005251, 0.028473515063524246, -...</td>\n",
       "      <td>{}</td>\n",
       "      <td>Open-ended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>\"Write a C++ program to find the nth Fibonacci...</td>\n",
       "      <td>#include&lt;iostream&gt;\\n\\nusing namespace std;\\n\\n...</td>\n",
       "      <td>Here is a C++ program to find the nth Fibonacc...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>model_a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.036859207, 0.10353846, -0.018434316, -0.02...</td>\n",
       "      <td>[-0.009891856, 0.08116202, 0.014044625, -0.064...</td>\n",
       "      <td>[-0.09364377, 0.040925734, 0.016252827, -0.078...</td>\n",
       "      <td>0.709220</td>\n",
       "      <td>0.824649</td>\n",
       "      <td>0.755761</td>\n",
       "      <td>[-0.03685920685529709, 0.10353846102952957, -0...</td>\n",
       "      <td>{}</td>\n",
       "      <td>Open-ended</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Given\\na=2, b=3, c=6;\\na=1.4, b=5, c=7;\\na=2, ...</td>\n",
       "      <td>In order to solve this problem, we need to fin...</td>\n",
       "      <td>We need to find the value of c given the value...</td>\n",
       "      <td>tie (bothbad)</td>\n",
       "      <td>model_a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[-0.003208244, 0.044472877, -0.047849033, 0.01...</td>\n",
       "      <td>[0.019388301, 0.074543595, -0.018501896, -0.03...</td>\n",
       "      <td>[0.00016731117, 0.049990736, -0.048009012, -0....</td>\n",
       "      <td>0.611023</td>\n",
       "      <td>0.702953</td>\n",
       "      <td>0.777603</td>\n",
       "      <td>[-0.0032082439865916967, 0.04447287693619728, ...</td>\n",
       "      <td>{(CODE, If)}</td>\n",
       "      <td>Closed-ended</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               prompt  \\\n",
       "98                                     Tell me a joke   \n",
       "64                 What is the industrial revolution?   \n",
       "28         what is a Calabi-Yau manifold ?\\n\\nAnswer:   \n",
       "18  \"Write a C++ program to find the nth Fibonacci...   \n",
       "39  Given\\na=2, b=3, c=6;\\na=1.4, b=5, c=7;\\na=2, ...   \n",
       "\n",
       "                                           response_a  \\\n",
       "98  Why did the carrot turn red?\\n\\nBecause it saw...   \n",
       "64  The Industrial Revolution refers to a period o...   \n",
       "28  A Calabi-Yau manifold is a type of mathematica...   \n",
       "18  #include<iostream>\\n\\nusing namespace std;\\n\\n...   \n",
       "39  In order to solve this problem, we need to fin...   \n",
       "\n",
       "                                           response_b   human_winner  \\\n",
       "98  A construction worker was walking when crashed...        model_b   \n",
       "64  The industrial revolution was a significant pe...        model_b   \n",
       "28  A Calabi-Yau manifold is a complex manifold th...        model_b   \n",
       "18  Here is a C++ program to find the nth Fibonacc...        model_b   \n",
       "39  We need to find the value of c given the value...  tie (bothbad)   \n",
       "\n",
       "   gpt_winner  label                                   prompt_embedding  \\\n",
       "98    model_a    0.0  [-0.013610002, -0.035938635, 0.02055572, 0.002...   \n",
       "64    model_a    0.0  [-0.025486542, 0.0061054714, -0.045459997, -0....   \n",
       "28    model_a    0.0  [-0.010430147, 0.028473515, -0.055231307, -0.0...   \n",
       "18    model_a    0.0  [-0.036859207, 0.10353846, -0.018434316, -0.02...   \n",
       "39    model_a    0.0  [-0.003208244, 0.044472877, -0.047849033, 0.01...   \n",
       "\n",
       "                                 response_a_embedding  \\\n",
       "98  [-0.050809518, -0.025566049, -0.0257295, 0.102...   \n",
       "64  [-0.0524989, -0.004233326, 0.00977435, 0.00209...   \n",
       "28  [-0.03338751, -0.04724372, -0.050808728, 0.015...   \n",
       "18  [-0.009891856, 0.08116202, 0.014044625, -0.064...   \n",
       "39  [0.019388301, 0.074543595, -0.018501896, -0.03...   \n",
       "\n",
       "                                 response_b_embedding  similarity_a_b  \\\n",
       "98  [-0.05158351, 0.022370216, 0.03135999, 0.06952...        0.156050   \n",
       "64  [-0.012855443, 0.004006175, 0.021647064, -0.02...        0.718032   \n",
       "28  [-0.047239825, 0.028733192, -0.03291552, 0.004...        0.734846   \n",
       "18  [-0.09364377, 0.040925734, 0.016252827, -0.078...        0.709220   \n",
       "39  [0.00016731117, 0.049990736, -0.048009012, -0....        0.611023   \n",
       "\n",
       "    similarity_a_c  similarity_b_c  \\\n",
       "98        0.210762        0.170802   \n",
       "64        0.749566        0.858142   \n",
       "28        0.858537        0.844449   \n",
       "18        0.824649        0.755761   \n",
       "39        0.702953        0.777603   \n",
       "\n",
       "                                             features detected_terms  \\\n",
       "98  [-0.013610001653432846, -0.03593863546848297, ...             {}   \n",
       "64  [-0.025486541911959648, 0.0061054714024066925,...             {}   \n",
       "28  [-0.01043014694005251, 0.028473515063524246, -...             {}   \n",
       "18  [-0.03685920685529709, 0.10353846102952957, -0...             {}   \n",
       "39  [-0.0032082439865916967, 0.04447287693619728, ...   {(CODE, If)}   \n",
       "\n",
       "        category  \n",
       "98    Open-ended  \n",
       "64    Open-ended  \n",
       "28    Open-ended  \n",
       "18    Open-ended  \n",
       "39  Closed-ended  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify_closed_ended(detected_terms):\n",
    "    # If any terms are detected, classify as closed-ended\n",
    "    if detected_terms:\n",
    "        return 'Closed-ended'\n",
    "    else:\n",
    "        return 'Open-ended'\n",
    "\n",
    "sampled_data['category'] = sampled_data['detected_terms'].apply(classify_closed_ended)\n",
    "sampled_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sampled_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m selected_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_a\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_b\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhuman_winner\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_winner\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m filtered_data \u001b[38;5;241m=\u001b[39m \u001b[43msampled_data\u001b[49m[selected_columns]\n\u001b[1;32m      3\u001b[0m filtered_data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m500\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sampled_data' is not defined"
     ]
    }
   ],
   "source": [
    "selected_columns = ['prompt', 'response_a', 'response_b', 'human_winner', 'gpt_winner', 'label', 'category']\n",
    "filtered_data = sampled_data[selected_columns]\n",
    "filtered_data.head(500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_to_csv import save_dataframe_to_csv\n",
    "\n",
    "save_dataframe_to_csv(filtered_data, filename='filtered_data', output_dir='/Users/doga/Desktop/chatbot arena project')\n",
    "print(f\"\\n✅ Saved disguised outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Open-ended and Closed-ended Prompts:\n",
      "category\n",
      "Open-ended      55.6\n",
      "Closed-ended    44.4\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "category_counts = filtered_data['category'].value_counts()\n",
    "total = category_counts.sum()\n",
    "percentages = (category_counts / total) * 100\n",
    "\n",
    "print(\"Percentage of Open-ended and Closed-ended Prompts:\")\n",
    "print(percentages)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
